{
  "hash": "4d228f7cabb69159461f1318b5e52a72",
  "result": {
    "markdown": "---\ntitle: \"Calls and computations\"\nauthor: \"Cody Peterson\"\ndate: \"2023-10-14\"\ncategories:\n    - \"LLMs and data\"\n---\n\n## Introduction\n\nThe Generative AI hype cycle has led to a new wave of terminology to understand. In this post, we'll use basic programming language to explain and explore \nthe concepts of \"chains\" of LLMs and retrieval-augmented generation (RAG) approaches to working with data.\n\nThis post assumes [basic familiarity with Marvin and Ibis](../llms-and-data-pt0) and [the three approaches to applying LLMs to data](../llms-and-data-pt1).\n\n::: {#08040ceb .cell execution_count=1}\n``` {.python .cell-code code-fold=\"true\"}\nimport ibis  # <1>\nimport marvin  # <1>\n\nfrom dotenv import load_dotenv  # <1>\n\nload_dotenv()  # <2>\n\ncon = ibis.connect(\"duckdb://penguins.ddb\")  # <3>\nt = ibis.examples.penguins.fetch()  # <3>\nt = con.create_table(\"penguins\", t.to_pyarrow(), overwrite=True)  # <3>\n```\n:::\n\n\n1. Import the libraries we need.\n2. Load the environment variable to setup Marvin to call our OpenAI account.\n3. Setup the demo datain an Ibis backend.\n\n::: {#0e3fa209 .cell execution_count=2}\n``` {.python .cell-code}\nimport ibis  # <1>\nimport marvin  # <1>\n\nfrom ibis.expr.schema import Schema  # <1>\nfrom ibis.expr.types.relations import Table  # <1>\n\nibis.options.interactive = True  # <2>\nmarvin.settings.llm_model = \"openai/gpt-4\"  # <2>\n\ncon = ibis.connect(\"duckdb://penguins.ddb\")  # <3>\nt = con.table(\"penguins\")  # <3>\n```\n:::\n\n\n1. Import Ibis and Marvin.\n2. Configure Ibis (interactive) and Marvin (GPT-4).\n3. Connect to the data and load a table into a variable.\n\n## Calls and computations\n\nWhen an AI platform's large language model API is called, it returns text as the result of some computation on input text. See the [LLM concept article](/concepts/llms.qmd) for details.\n\n### Calls\n\nA call is just that -- a call to **something**. In Python, this is typically always something else in Python, that itself may make calls to other programming languages or external services.\n\n::: {#f06217f8 .cell execution_count=3}\n``` {.python .cell-code}\n@marvin.ai_fn  # <1>\ndef _generate_sql_select(\n    text: str, table_name: str, table_schema: Schema\n) -> str:  # <1>\n    \"\"\"Generate SQL SELECT from text.\"\"\"  # <1>\n\n\ndef sql_from_text(text: str, t: Table) -> Table:  # <2>\n    \"\"\"Run SQL from text.\"\"\"  # <2>\n    return t.sql(_generate_sql_select(text, t.get_name(), t.schema()).strip(\";\"))  # <2>\n```\n:::\n\n\n1. A non-deterministic, LLM-powered AI function.\n2. A deterministic, human-authored function that calls the AI function.\n\n\n\n### Computations\n\nA computation is just that -- a computation of **something**. In general, a computation is represented by a system that takes an input and returns an output.\n\n## Comparison to MLOps and DevOps\n\n## Summary\n\n## Next steps\n\nYou can get involved with [Ibis\nBirdbrain](https://github.com/ibis-project/ibis-birdbrain), our open-source data\n& AI project for building next-generation natural language interfaces to data.\n\n[Read the next post in this series](../llms-and-data-pt3).\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}
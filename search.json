[
  {
    "objectID": "how-to/input-output/basics.html",
    "href": "how-to/input-output/basics.html",
    "title": "Basic input/output",
    "section": "",
    "text": "You can…"
  },
  {
    "objectID": "posts/llms-and-data-pt1/index.html",
    "href": "posts/llms-and-data-pt1/index.html",
    "title": "Three approaches",
    "section": "",
    "text": "The thought of using natural language to transform and analyze data is appealing. This post assumes familiarity with Marvin and Ibis – read the preivous post in the series for a quick overview."
  },
  {
    "objectID": "posts/llms-and-data-pt1/index.html#introduction",
    "href": "posts/llms-and-data-pt1/index.html#introduction",
    "title": "Three approaches",
    "section": "",
    "text": "The thought of using natural language to transform and analyze data is appealing. This post assumes familiarity with Marvin and Ibis – read the preivous post in the series for a quick overview."
  },
  {
    "objectID": "posts/llms-and-data-pt1/index.html#approaches",
    "href": "posts/llms-and-data-pt1/index.html#approaches",
    "title": "Three approaches",
    "section": "Approaches",
    "text": "Approaches\nWhen discussed at Voltron Data, we identified three distinct approaches to applying LLMs to data analytics that can be implemented today:\n\nLLM writes an analytic code\nLLM writes an analytic subroutine\nUse LLM in an analytic subroutine\n\nWhile these three approaches are not an exhaustive list of how LLMs can be applied to data, they can be easily understood and implemented with Ibis and Marvin. Together with these two open-source tools, we can build a natural language interface for data analytics that supports 18+ backends.\nBut first, let’s demonstrate the three approaches in code.\n\nApproach 1: LLM writes analytic code\nState of the art (SoTA) LLMs are decent at generating SQL out of the box. We can be clever to handle errors, retries, and more, but in its simplest form:\n\n\nCode\n1import ibis\nimport marvin\n\nfrom rich import print\nfrom time import sleep\nfrom dotenv import load_dotenv\n\n2load_dotenv()\n\n3con = ibis.connect(\"duckdb://penguins.ddb\")\nt = ibis.examples.penguins.fetch()\nt = con.create_table(\"penguins\", t.to_pyarrow(), overwrite=True)\n\n\n\n1\n\nImport the libraries we need.\n\n2\n\nLoad the environment variable to setup Marvin to call our OpenAI account.\n\n3\n\nSetup the demo datain an Ibis backend.\n\n\n\n\n\n1import ibis\nimport marvin\n\nfrom ibis.expr.schema import Schema\nfrom ibis.expr.types.relations import Table\n\n\n2ibis.options.interactive = True\nmarvin.settings.llm_model = \"openai/gpt-4\"\n\n\n1\n\nImport Ibis and Marvin.\n\n2\n\nConfigure Ibis and Marvin\n\n\n\n\n\n1@marvin.ai_fn\ndef _generate_sql_select(\n    text: str, table_name: str, table_schema: Schema\n) -&gt; str:\n    \"\"\"Generate SQL SELECT from text.\"\"\"\n\n\n2def sql_from_text(text: str, t: Table) -&gt; Table:\n    \"\"\"Run SQL from text.\"\"\"\n    return t.sql(_generate_sql_select(text, t.get_name(), t.schema()).strip(\";\"))\n\n\n1\n\nA non-deterministic, LLM-powered AI function.\n\n2\n\nA deterministic, human-authored function that calls the AI function.\n\n\n\n\n\nt2 = sql_from_text(\"the unique combination of species and islands\", t)\nt2\n\n┏━━━━━━━━━━━┳━━━━━━━━━━━┓\n┃ species   ┃ island    ┃\n┡━━━━━━━━━━━╇━━━━━━━━━━━┩\n│ string    │ string    │\n├───────────┼───────────┤\n│ Adelie    │ Torgersen │\n│ Adelie    │ Biscoe    │\n│ Adelie    │ Dream     │\n│ Gentoo    │ Biscoe    │\n│ Chinstrap │ Dream     │\n└───────────┴───────────┘\n\n\n\n\n\nCode\n1sleep(3)\n\n\n\n1\n\nAvoid rate-limiting by waiting.\n\n\n\n\n\nt3 = sql_from_text(\n    \"the unique combination of species and islands, with their counts, ordered from highest to lowest, and name that column just 'count'\",\n    t,\n)\nt3\n\n┏━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━┓\n┃ species   ┃ island    ┃ count ┃\n┡━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━┩\n│ string    │ string    │ int64 │\n├───────────┼───────────┼───────┤\n│ Gentoo    │ Biscoe    │   124 │\n│ Chinstrap │ Dream     │    68 │\n│ Adelie    │ Dream     │    56 │\n│ Adelie    │ Torgersen │    52 │\n│ Adelie    │ Biscoe    │    44 │\n└───────────┴───────────┴───────┘\n\n\n\n\n\nCode\n1sleep(3)\n\n\n\n1\n\nAvoid rate-limiting by waiting.\n\n\n\n\nThis works well-enough for simple cases and can be expanded to handle complex ones. In many scenarios, it may be easier to express a query in English or another language than to write it in SQL, especially if working across multiple SQL dialects.\nSQL isn’t a proper standard, with many dialects that can complicate the issue. Ibis works around this in a standard Python API for transformation code, but still makes compromises to support many backends. Substrait is a new project that aims to solve this problem by providing a standard, portable, and extensible API for data transformation code. Substrait is still in the early stages of development, but it’s worth keeping an eye on and will be adopted in Ibis once supported across many data platforms.\nFor now, we’ll focus on generating SQL and Python analytical code with LLMs.\n\n\nApproach 2: LLM writes an analytical subroutine\nIf more complex logic needs to be expressed, SoTA LLMs are also decent at writing Python and a number of other programming languages that are used in analytical subroutines. Many data platforms support user-defined functions (UDFs) in Python or some other language. We’ll stick to scalar Python UDFs via DuckDB to demonstrate the concept:\n\n1@marvin.ai_fn\ndef _generate_python_function(text: str) -&gt; str:\n    \"\"\"Generate a simple, typed, correct Python function from text.\"\"\"\n\n\n2def create_udf_from_text(text: str) -&gt; str:\n    \"\"\"Create a UDF from text.\"\"\"\n    return f\"\"\"\nimport ibis\n\n@ibis.udf.scalar.python\n{_generate_python_function(text)}\n\"\"\".strip()\n\n\n1\n\nA non-deterministic, LLM-powered AI function.\n\n2\n\nA deterministic, human-authored function that calls the AI function.\n\n\n\n\n\nudf = create_udf_from_text(\n    \"a function named count_vowels that given an input string, returns an int w/ the number of vowels (y_included as a boolean option defaulted to False)\"\n)\nprint(udf)\nexec(udf)\n\nimport ibis\n\n@ibis.udf.scalar.python\ndef count_vowels(input_string: str, y_included: bool = False) -&gt; int:\n    vowels = 'aeiou'\n    if y_included:\n        vowels += 'y'\n    return sum(1 for char in input_string if char.lower() in vowels)\n\n\n\n\n\nCode\n1sleep(3)\n\n\n\n1\n\nAvoid rate-limiting by waiting.\n\n\n\n\n\nt4 = t3.mutate(\n    species_vowel_count=count_vowels(t3.species),\n    island_vowel_count=count_vowels(t3.island),\n)\nt4\n\n┏━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n┃ species   ┃ island    ┃ count ┃ species_vowel_count ┃ island_vowel_count ┃\n┡━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━┩\n│ string    │ string    │ int64 │ int64               │ int64              │\n├───────────┼───────────┼───────┼─────────────────────┼────────────────────┤\n│ Gentoo    │ Biscoe    │   124 │                   3 │                  3 │\n│ Chinstrap │ Dream     │    68 │                   2 │                  2 │\n│ Adelie    │ Dream     │    56 │                   4 │                  2 │\n│ Adelie    │ Torgersen │    52 │                   4 │                  3 │\n│ Adelie    │ Biscoe    │    44 │                   4 │                  3 │\n└───────────┴───────────┴───────┴─────────────────────┴────────────────────┘\n\n\n\n\n\nCode\n1sleep(3)\n\n\n\n1\n\nAvoid rate-limiting by waiting.\n\n\n\n\nIn this case, there’s no reason not to have a human in the loop reviewing the output code and committing it for production use. This could be useful for quick prototyping or, given a box of tools in the form of UDFs, working through a natural language interface.\n\n\nApproach 3: Use LLM in an analytical subroutine\nWe can also call the LLM once-per-row in the table via a subroutine. For variety, we’ll use an AI model instead of an AI function:\n\n1from pydantic import BaseModel, Field\n\n# decrease cost\n2marvin.settings.llm_model = \"openai/gpt-3.5-turbo-16k\"\n\n\n3@marvin.ai_model\nclass VowelCounter(BaseModel):\n    \"\"\"Count vowels in a string.\"\"\"\n\n    include_y: bool = Field(False, description=\"Include 'y' as a vowel.\")\n    # num_a: int = Field(..., description=\"The number of 'a' vowels.\")\n    # num_e: int = Field(..., description=\"The number of 'e' vowels.\")\n    # num_i: int = Field(..., description=\"The number of 'i' vowels.\")\n    # num_o: int = Field(..., description=\"The number of 'o' vowels.\")\n    # num_u: int = Field(..., description=\"The number of 'u' vowels.\")\n    # num_y: int = Field(..., description=\"The number of 'y' vowels.\")\n    num_total: int = Field(..., description=\"The total number of vowels.\")\n\n\n4VowelCounter(\"hello world\")\n\n\n1\n\nAdditional imports for Pydantic.\n\n2\n\nConfigure Marvin to use a cheaper model.\n\n3\n\nA non-deterministic, LLM-powered AI model.\n\n4\n\nCall the AI model on some text.\n\n\n\n\nVowelCounter(include_y=False, num_total=3)\n\n\nThen we’ll have the LLM write the UDF, just to be fancy:\n\nudf = create_udf_from_text(\n    \"a function named count_vowels_ai that given an input string, calls VowelCounter on it and returns the num_total attribute of that result\"\n)\nprint(udf)\nexec(udf)\n\nimport ibis\n\n@ibis.udf.scalar.python\ndef count_vowels_ai(input_string: str) -&gt; int:\n    result = VowelCounter(input_string)\n    return result.num_total\n\n\n\n\n\nCode\n1sleep(3)\n\n\n\n1\n\nAvoid rate-limiting by waiting.\n\n\n\n\n\nt5 = t3.mutate(\n    species_vowel_count=count_vowels_ai(t3.species),\n    island_vowel_count=count_vowels_ai(t3.island),\n)\nt5\n\n┏━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n┃ species   ┃ island    ┃ count ┃ species_vowel_count ┃ island_vowel_count ┃\n┡━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━┩\n│ string    │ string    │ int64 │ int64               │ int64              │\n├───────────┼───────────┼───────┼─────────────────────┼────────────────────┤\n│ Gentoo    │ Biscoe    │   124 │                   3 │                  3 │\n│ Chinstrap │ Dream     │    68 │                   2 │                  1 │\n│ Adelie    │ Dream     │    56 │                   3 │                  2 │\n│ Adelie    │ Torgersen │    52 │                   3 │                  3 │\n│ Adelie    │ Biscoe    │    44 │                   3 │                  3 │\n└───────────┴───────────┴───────┴─────────────────────┴────────────────────┘\n\n\n\nNotice that in this UDF, unlike in the previous example, a LLM is being called (possibly several times) for each row in the table. This is a very expensive operation and we’ll need to be careful about how we use it in practice.\n\n\nCode\n1sleep(3)\n\n\n\n1\n\nAvoid rate-limiting by waiting."
  },
  {
    "objectID": "posts/llms-and-data-pt1/index.html#summary",
    "href": "posts/llms-and-data-pt1/index.html#summary",
    "title": "Three approaches",
    "section": "Summary",
    "text": "Summary\nTo summarize this post:\n\nfrom rich import print\n\nwith open(\"index.qmd\", \"r\") as f:\n    self_text = f.read()\n\n# increease accuracy\nmarvin.settings.llm_model = \"openai/gpt-4\"\n\n@marvin.ai_model\nclass Summary(BaseModel):\n    \"\"\"Summary of text.\"\"\"\n\n    summary_line: str = Field(..., description=\"The one-line summary of the text.\")\n    summary_paragraph: str = Field(\n        ..., description=\"The one-paragraph summary of the text.\"\n    )\n    conclusion: str = Field(\n        ..., description=\"The conclusion the reader should draw from the text.\"\n    )\n    key_points: list[str] = Field(..., description=\"The key points of the text.\")\n    critiques: list[str] = Field(\n        ..., description=\"Professional, fair critiques of the text.\"\n    )\n    suggested_improvements: list[str] = Field(\n        ..., description=\"Suggested improvements for the text.\"\n    )\n    sentiment: float = Field(..., description=\"The sentiment of the text.\")\n    sentiment_label: str = Field(..., description=\"The sentiment label of the text.\")\n    author_bias: str = Field(..., description=\"The author bias of the text.\")\n\n\nprint(Summary(self_text))\n\nSummary(\n    summary_line='The text is a blog post by Cody Peterson published on 13th October 2023, discussing three \ndistinct approaches to applying Language Learning Models (LLMs) to data analytics through Marvin and Ibis \nopen-source tools.',\n    summary_paragraph=\"The author, Cody Peterson, elaborates on three different methods of applying Language \nLearning Models (LLMs) to data analytics. These include: LLM writing an analytic code, LLM writing an analytic \nsubroutine, and using LLM in an analytic subroutine. He further demonstrates each approach through code examples. \nThese methods have been discussed at Voltron Data and can be implemented today. The tools used for these \nimplementations are Marvin and Ibis, which are open-source. The text also suggests that a natural language \ninterface for data analytics can be built using these methods. The post concludes with a call to involvement with \nthe open-source project 'Ibis Birdbrain'.\",\n    conclusion=\"The three methods discussed for applying LLMs to data analytics offer valuable techniques for \ntransforming and analyzing data. These methods can be readily implemented with the open-source tools Marvin and \nIbis. The author encourages readers to participate in the 'Ibis Birdbrain' open-source project for further \nexploration of natural language interfaces to data.\",\n    key_points=[\n        'The post discusses three distinct approaches to applying LLMs to data analytics.',\n        'The first approach involves writing an analytic code using LLM, and the second approach involves writing \nan analytic subroutine through LLM.',\n        'The third approach is to use LLM in an analytic subroutine.',\n        'The author uses Marvin and Ibis for implementing these approaches.',\n        'The text suggests that these methods can be used to build a natural language interface for data analytics \nsupporting 18+ backends.',\n        \"The author encourages readers to participate in the 'Ibis Birdbrain' open-source project.\"\n    ],\n    critiques=[\n        'The author could have expanded on the potential limitations or challenges of implementing these \napproaches.',\n        'Frequent use of technical jargon might make the content difficult for beginners or non-technical readers \nto comprehend.'\n    ],\n    suggested_improvements=[\n        'A glossary of the technical terms used throughout the text could be included to assist readers from \nnon-technical backgrounds.',\n        'The author could include more real-world examples or case studies to demonstrate the effectiveness of \nthese approaches.'\n    ],\n    sentiment=0.7,\n    sentiment_label='Positive',\n    author_bias='The author seems to have a favorable bias towards the use of LLMs in data analytics, and \nopen-source tools Marvin and Ibis.'\n)"
  },
  {
    "objectID": "posts/llms-and-data-pt1/index.html#next-steps",
    "href": "posts/llms-and-data-pt1/index.html#next-steps",
    "title": "Three approaches",
    "section": "Next steps",
    "text": "Next steps\nYou can get involved with Ibis Birdbrain, our open-source data & AI project for building next-generation natural language interfaces to data.\nRead the next post in this series."
  },
  {
    "objectID": "posts/llms-and-data-pt3/index.html",
    "href": "posts/llms-and-data-pt3/index.html",
    "title": "Modular and composable",
    "section": "",
    "text": "# | code-fold: true\n1import ibis\nimport marvin\n\nfrom dotenv import load_dotenv\n\n2load_dotenv()\n\n3con = ibis.connect(\"duckdb://penguins.ddb\")\nt = ibis.examples.penguins.fetch()\nt = con.create_table(\"penguins\", t.to_pyarrow(), overwrite=True)\n\n1\n\nImport the libraries we need.\n\n2\n\nLoad the environment variable to setup Marvin to call our OpenAI account.\n\n3\n\nSetup the demo datain an Ibis backend.\n\n\n1import ibis\nimport marvin\n\nfrom ibis.expr.schema import Schema\nfrom ibis.expr.types.relations import Table\n\n2ibis.options.interactive = True\nmarvin.settings.llm_model = \"openai/gpt-4\"\n\n3con = ibis.connect(\"duckdb://penguins.ddb\")\nt = con.table(\"penguins\")\n\n1\n\nImport Ibis and Marvin.\n\n2\n\nConfigure Ibis (interactive) and Marvin (GPT-4).\n\n3\n\nConnect to the data and load a table into a variable.\n\n\n1@marvin.ai_fn\ndef _generate_sql_select(\n    text: str, table_name: str, table_schema: Schema\n) -&gt; str:\n    \"\"\"Generate SQL SELECT from text.\"\"\"\n\n\n2def sql_from_text(text: str, t: Table) -&gt; Table:\n    \"\"\"Run SQL from text.\"\"\"\n    return t.sql(_generate_sql_select(text, t.get_name(), t.schema()).strip(\";\"))\n\n1\n\nA non-deterministic, LLM-powered AI function.\n\n2\n\nA deterministic, human-authored function that calls the AI function.\n\n\nt2 = sql_from_text(\"the unique combination of species and islands\", t)\nt2\nt3 = sql_from_text(\n    \"the unique combination of species and islands, with their counts, ordered from highest to lowest, and name that column just 'count'\",\n    t,\n)\nt3"
  },
  {
    "objectID": "posts/llms-and-data-pt3/index.html#introduction",
    "href": "posts/llms-and-data-pt3/index.html#introduction",
    "title": "Modular and composable",
    "section": "",
    "text": "# | code-fold: true\n1import ibis\nimport marvin\n\nfrom dotenv import load_dotenv\n\n2load_dotenv()\n\n3con = ibis.connect(\"duckdb://penguins.ddb\")\nt = ibis.examples.penguins.fetch()\nt = con.create_table(\"penguins\", t.to_pyarrow(), overwrite=True)\n\n1\n\nImport the libraries we need.\n\n2\n\nLoad the environment variable to setup Marvin to call our OpenAI account.\n\n3\n\nSetup the demo datain an Ibis backend.\n\n\n1import ibis\nimport marvin\n\nfrom ibis.expr.schema import Schema\nfrom ibis.expr.types.relations import Table\n\n2ibis.options.interactive = True\nmarvin.settings.llm_model = \"openai/gpt-4\"\n\n3con = ibis.connect(\"duckdb://penguins.ddb\")\nt = con.table(\"penguins\")\n\n1\n\nImport Ibis and Marvin.\n\n2\n\nConfigure Ibis (interactive) and Marvin (GPT-4).\n\n3\n\nConnect to the data and load a table into a variable.\n\n\n1@marvin.ai_fn\ndef _generate_sql_select(\n    text: str, table_name: str, table_schema: Schema\n) -&gt; str:\n    \"\"\"Generate SQL SELECT from text.\"\"\"\n\n\n2def sql_from_text(text: str, t: Table) -&gt; Table:\n    \"\"\"Run SQL from text.\"\"\"\n    return t.sql(_generate_sql_select(text, t.get_name(), t.schema()).strip(\";\"))\n\n1\n\nA non-deterministic, LLM-powered AI function.\n\n2\n\nA deterministic, human-authored function that calls the AI function.\n\n\nt2 = sql_from_text(\"the unique combination of species and islands\", t)\nt2\nt3 = sql_from_text(\n    \"the unique combination of species and islands, with their counts, ordered from highest to lowest, and name that column just 'count'\",\n    t,\n)\nt3"
  },
  {
    "objectID": "posts/llms-and-data-pt3/index.html#summary",
    "href": "posts/llms-and-data-pt3/index.html#summary",
    "title": "Modular and composable",
    "section": "Summary",
    "text": "Summary\nTo summarize this post:\nfrom rich import print\nfrom pydantic import BaseModel, Field\n\nwith open(\"index.qmd\", \"r\") as f:\n    self_text = f.read()\n\n# save some money and avoid rate limiting\nmarvin.settings.llm_model = \"openai/gpt-3.5-turbo-16k\"\n\n@marvin.ai_model\nclass Summary(BaseModel):\n    \"\"\"Summary of text.\"\"\"\n\n    summary_line: str = Field(..., description=\"The one-line summary of the text.\")\n    summary_paragraph: str = Field(\n        ..., description=\"The one-paragraph summary of the text.\"\n    )\n    conclusion: str = Field(\n        ..., description=\"The conclusion the reader should draw from the text.\"\n    )\n    key_points: list[str] = Field(..., description=\"The key points of the text.\")\n    critiques: list[str] = Field(\n        ..., description=\"Professional, fair critiques of the text.\"\n    )\n    suggested_improvements: list[str] = Field(\n        ..., description=\"Suggested improvements for the text.\"\n    )\n    sentiment: float = Field(..., description=\"The sentiment of the text.\")\n    sentiment_label: str = Field(..., description=\"The sentiment label of the text.\")\n    author_bias: str = Field(..., description=\"The author bias of the text.\")\n\n\nprint(Summary(self_text))"
  },
  {
    "objectID": "posts/llms-and-data-pt3/index.html#next-steps",
    "href": "posts/llms-and-data-pt3/index.html#next-steps",
    "title": "Modular and composable",
    "section": "Next steps",
    "text": "Next steps\nYou can get involved with Ibis Birdbrain, our open-source data & AI project for building next-generation natural language interfaces to data.\nRead the next post in this series."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ibis Birdbrain",
    "section": "",
    "text": "Why?\n  \n  \n    \n     Installation\n  \n  \n    \n     Tutorial\n  \n  \n    \n     GitHub\n  \n  \n    \n     Chat\n  \n  \n    \n     RSS"
  },
  {
    "objectID": "index.html#demo",
    "href": "index.html#demo",
    "title": "Ibis Birdbrain",
    "section": "Demo",
    "text": "Demo\nTo get started…\nfrom ibis_birdbrain.bots.birdbrain import bot\n\nbot(\"who're you and what can you do?\")\nbirdbrain:\n\nHello! I'm known as 'birdbrain', but my full name is 'Ibis Birdbrain'. I was\ncreated by the Ibis developers to assist data practitioners with their projects.\nI have a variety of tools at my disposal. Here are some of the things I can do:\n\n1. Access a data platform via Ibis.\n2. Run SQL queries.\n3. Generate and execute Python code.\n4. Search the internet and summarize information.\n5. Read files and summarize them.\n\nMy purpose is to facilitate your data analysis process and provide assistance\nwith tools like Ibis, SQL, and Python. Please let me know how I can assist you\ntoday!\n\nFor more detailed information, you can check my documentation and source code:\n\n- Ibis Documentation: [Ibis Docs](https://www.ibis-project.org)\n- Birdbrain Source Code: (https://github.com/ibis-project/ibis-birdbrain)\n\nNote that I always rely on factual and queried data for the information I\nprovide, and I will always cite my sources.\nbot(\"what's the meaning of life?\")\nbirdbrain:\n\nThe meaning of life, according to my current state, is 42! This might be a\nreference to \"The Hitchhiker's Guide to the Galaxy\" by Douglas Adams, where the\n\"Answer to the Ultimate Question of Life, The Universe, and Everything\" is\nhumorously stated as 42. However, the true meaning of life might be different\nfor each individual and could be found in personal growth, relationships,\nhelping others, or in the pursuit of knowledge. Always a fascinating topic to\nponder upon!"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nModular and composable\n\n\n\nLLMs and data\n\n\n\n\n\n\n\nCody Peterson\n\n\nOct 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCalls and computations\n\n\n\nLLMs and data\n\n\n\n\n\n\n\nCody Peterson\n\n\nOct 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThree approaches\n\n\n\nLLMs and data\n\n\n\n\n\n\n\nCody Peterson\n\n\nOct 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn introduction to Marvin and Ibis\n\n\n\nLLMs and data\n\n\n\n\n\n\n\nCody Peterson\n\n\nOct 12, 2023\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "tutorials/rest.html",
    "href": "tutorials/rest.html",
    "title": "Tutorial: REST API",
    "section": "",
    "text": "TBD"
  },
  {
    "objectID": "tutorials/rest.html#prerequisites",
    "href": "tutorials/rest.html#prerequisites",
    "title": "Tutorial: REST API",
    "section": "",
    "text": "TBD"
  },
  {
    "objectID": "tutorials/cli.html",
    "href": "tutorials/cli.html",
    "title": "Tutorial: command-line interface (CLI)",
    "section": "",
    "text": "TBD"
  },
  {
    "objectID": "tutorials/cli.html#prerequisites",
    "href": "tutorials/cli.html#prerequisites",
    "title": "Tutorial: command-line interface (CLI)",
    "section": "",
    "text": "TBD"
  },
  {
    "objectID": "concepts/llms.html",
    "href": "concepts/llms.html",
    "title": "Large language models",
    "section": "",
    "text": "Large language models (LLMs) represent decades of research and development of neural networks. While relatively impressive LLMs have been around for years, recent innovations have made it possible to create instruction-following, conversational bots that can perform tasks on behalf of the user.\nWe are primarily concerned with applying LLMs to data, but we’ll take a brief look at how they work and why we should use them."
  },
  {
    "objectID": "concepts/platforms.html",
    "href": "concepts/platforms.html",
    "title": "Data and AI platforms",
    "section": "",
    "text": "Data and AI platforms are…"
  },
  {
    "objectID": "why.html",
    "href": "why.html",
    "title": "Why Ibis Birdbrain?",
    "section": "",
    "text": "Ibis is the portable Python dataframe library.\nIbis Birdbrain is the portable Python AI-powered data bot, built on Ibis with support for all data platforms Ibis’s 18+ backends support. Ibis Birdbrain is also built on Marvin with support for all AI platforms Marvin supports.\n\n\n\n\nWhen things don’t work as they should, it often means that standards are absent.\n- The International Organization for Standardization (ISO)\n\n- The Composable Codex\n\n\n\n\nComposable data systems are MICE: modular, interoperable, customizable, and extensible.\nIbis Birdbrain aims to bring these values to a data + AI framework that makes working with LLMs delightful and easy, for individual hobbiests or the more advanced technology organizations."
  },
  {
    "objectID": "why.html#standards",
    "href": "why.html#standards",
    "title": "Why Ibis Birdbrain?",
    "section": "",
    "text": "When things don’t work as they should, it often means that standards are absent.\n- The International Organization for Standardization (ISO)\n\n- The Composable Codex"
  },
  {
    "objectID": "why.html#composable-data-systems-are-mice",
    "href": "why.html#composable-data-systems-are-mice",
    "title": "Why Ibis Birdbrain?",
    "section": "",
    "text": "Composable data systems are MICE: modular, interoperable, customizable, and extensible.\nIbis Birdbrain aims to bring these values to a data + AI framework that makes working with LLMs delightful and easy, for individual hobbiests or the more advanced technology organizations."
  },
  {
    "objectID": "release_notes.html",
    "href": "release_notes.html",
    "title": "Release notes",
    "section": "",
    "text": "Release notes\nTBD\n\n\n\n\n Back to top"
  },
  {
    "objectID": "concepts/ops.html",
    "href": "concepts/ops.html",
    "title": "LLMOps, MLOps, DevOps",
    "section": "",
    "text": "The ML landscape is plagued by “the toy problem” – building something cool is easy, putting something in production is hard."
  },
  {
    "objectID": "concepts/user-interfaces.html",
    "href": "concepts/user-interfaces.html",
    "title": "User interfaces",
    "section": "",
    "text": "A user interface (UI) in our context is the mechanism by which a human interacts with software."
  },
  {
    "objectID": "demo.html",
    "href": "demo.html",
    "title": "demo",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "tutorials/python.html",
    "href": "tutorials/python.html",
    "title": "Tutorial: (interactive) Python",
    "section": "",
    "text": "TBD"
  },
  {
    "objectID": "tutorials/python.html#prerequisites",
    "href": "tutorials/python.html#prerequisites",
    "title": "Tutorial: (interactive) Python",
    "section": "",
    "text": "TBD"
  },
  {
    "objectID": "contribute/contributing.html",
    "href": "contribute/contributing.html",
    "title": "Contributing",
    "section": "",
    "text": "To contribute…"
  },
  {
    "objectID": "contribute/contributing.html#required-dependencies",
    "href": "contribute/contributing.html#required-dependencies",
    "title": "Contributing",
    "section": "",
    "text": "To contribute…"
  },
  {
    "objectID": "install.html",
    "href": "install.html",
    "title": "Installation and setup",
    "section": "",
    "text": "This page describes how to install and setup Ibis Birdbrain.\n\n\npip install ibis-birdbrain\n\n\n\nOnly DuckDB supported for now. All 18+ Ibis backends coming soon.\n\n\n\nOnly OpenAI models work well due to the logit bias trick.\nTODO: document setup."
  },
  {
    "objectID": "install.html#install-from-pypi",
    "href": "install.html#install-from-pypi",
    "title": "Installation and setup",
    "section": "",
    "text": "pip install ibis-birdbrain"
  },
  {
    "objectID": "install.html#data-platform-setup",
    "href": "install.html#data-platform-setup",
    "title": "Installation and setup",
    "section": "",
    "text": "Only DuckDB supported for now. All 18+ Ibis backends coming soon."
  },
  {
    "objectID": "install.html#ai-platform-setup",
    "href": "install.html#ai-platform-setup",
    "title": "Installation and setup",
    "section": "",
    "text": "Only OpenAI models work well due to the logit bias trick.\nTODO: document setup."
  },
  {
    "objectID": "posts/llms-and-data-pt0/index.html",
    "href": "posts/llms-and-data-pt0/index.html",
    "title": "An introduction to Marvin and Ibis",
    "section": "",
    "text": "In this “LLMs and data” series, we’ll explore how to apply large-language models (LLMs) to data analytics. We’ll walk through the steps to build Ibis Birdbrain.\nThroughout the series, we’ll be using Marvin and Ibis. A brief introduction to each is provided below."
  },
  {
    "objectID": "posts/llms-and-data-pt0/index.html#introduction",
    "href": "posts/llms-and-data-pt0/index.html#introduction",
    "title": "An introduction to Marvin and Ibis",
    "section": "",
    "text": "In this “LLMs and data” series, we’ll explore how to apply large-language models (LLMs) to data analytics. We’ll walk through the steps to build Ibis Birdbrain.\nThroughout the series, we’ll be using Marvin and Ibis. A brief introduction to each is provided below."
  },
  {
    "objectID": "posts/llms-and-data-pt0/index.html#marvin",
    "href": "posts/llms-and-data-pt0/index.html#marvin",
    "title": "An introduction to Marvin and Ibis",
    "section": "Marvin",
    "text": "Marvin\nMarvin is an AI engineering framework that makes it easy to build up to an interactive conversational application. Using additionalpython open-source tools, we can apply this to the command-line interface (CLI) and REST API services.\nMarvin makes calls to an AI platform. You typically use an API key set as an environment variable – in this case, we’ll load a .env file that contians secrets for the AI platform that Marvin will use. We also set the large language model model.\n\n1import marvin\n\nfrom rich import print\nfrom time import sleep\nfrom dotenv import load_dotenv\n\n2load_dotenv()\n\n# increase accuracy\n3marvin.settings.llm_model = \"openai/gpt-4\"\n# decrease cost\n# marvin.settings.llm_model = \"openai/gpt-3.5-turbo\"\n\n4test_str = \"working with data and LLMs on 18+ data platforms is easy!\"\ntest_str\n\n\n1\n\nImport the libraries we need.\n\n2\n\nLoad the environment variable to setup Marvin to call our OpenAI account.\n\n3\n\nConfigure the LLM model to use.\n\n4\n\nSome text to test on\n\n\n\n\n'working with data and LLMs on 18+ data platforms is easy!'\n\n\n\nFunctions\nAI functions are one of the building blocks in Marvin and allow yout to specify a typedpython function with no code – only a docstring – to achieve a wide variety of tasks.\nWe’ll demonstrate this with an AI function that trnaslates text:\n\n@marvin.ai_fn\ndef translate(text: str, from_: str = \"English\", to: str = \"Spanish\") -&gt; str:\n    \"\"\"translates the text\"\"\"\n\ntranslate(test_str)\n\n'¡Trabajar con datos y LLMs en más de 18 plataformas de datos es fácil!'\n\n\n\n\nCode\n1sleep(1)\n\n\n\n1\n\nAvoid rate-limiting by waiting.\n\n\n\n\n\ntranslate(translate(test_str), from_=\"Spanish\", to=\"English\")\n\n'Working with data and LLMs on over 18 data platforms is easy!'\n\n\n\n\nCode\n1sleep(3)\n\n\n\n1\n\nAvoid rate-limiting by waiting.\n\n\n\n\n\n\nModels\nAI models are another building block for generatingpython classes from input text. It’s a great way to build structured data from unstructured data that can be customized for your needs.\nWe’ll demosntrate this with an AI model that translates text:\n\nfrom pydantic import BaseModel, Field\n\n# decrease cost\nmarvin.settings.llm_model = \"openai/gpt-3.5-turbo\"\n\n@marvin.ai_model\nclass ExtractParts(BaseModel):\n    \"\"\"Extracts parts of a sentence\"\"\"\n    subject: str = Field(..., description=\"The subject of the sentence.\")\n    predicate: str = Field(..., description=\"The predicate of the sentence.\")\n    objects: list[str] = Field(..., description=\"The objects of the sentence.\")\n    modifiers: list[str] = Field(..., description=\"The modifiers of the sentence.\")\n\nExtractParts(test_str)\n\nExtractParts(subject='working with data and LLMs', predicate='is', objects=['easy'], modifiers=['on 18+ data platforms'])\n\n\n\n\nCode\n1sleep(1)\n\n\n\n1\n\nAvoid rate-limiting by waiting.\n\n\n\n\n\n\nClassifiers\nAI classifiers are another building block for generatingpython classes from input text. It’s the most efficient (time and cost) method for applying LLMs as it only results in a single output token, selecting an output in a specified Enum.\nWe’ll demonstrate this by classifying the language of some text:\n\nfrom enum import Enum\n\n# increase accuracy\nmarvin.settings.llm_model = \"openai/gpt-4\"\n\n@marvin.ai_classifier\nclass IdentifyLanguage(Enum):\n    \"\"\"Identifies the language of the text\"\"\"\n\n    english = \"English\"\n    spanish = \"Spanish\"\n\n\nIdentifyLanguage(test_str).value\n\n'English'\n\n\n\n\nCode\n1sleep(1)\n\n\n\n1\n\nAvoid rate-limiting by waiting.\n\n\n\n\n\nIdentifyLanguage(translate(test_str)).value\n\n'Spanish'\n\n\n\n\nCode\n1sleep(3)\n\n\n\n1\n\nAvoid rate-limiting by waiting."
  },
  {
    "objectID": "posts/llms-and-data-pt0/index.html#ibis",
    "href": "posts/llms-and-data-pt0/index.html#ibis",
    "title": "An introduction to Marvin and Ibis",
    "section": "Ibis",
    "text": "Ibis\nIbis is the portable Python dataframe library that is modular and composable.\nIbis makes calls to a data platform, providing an API but pushing the compute to (local or remote) query engines and storage. DuckDB is the default and we’ll typically use it for demo puroses. You can work with an in-memory instance, but we’ll often create a database file from example data:\n\n1import ibis\n\n2con = ibis.connect(\"duckdb://penguins.ddb\")\nt = ibis.examples.penguins.fetch()\nt = con.create_table(\"penguins\", t.to_pyarrow(), overwrite=True)\n\n\n1\n\nImport the libraries we need.\n\n2\n\nSetup the demo datain an Ibis backend.\n\n\n\n\nYou will typically connect to an existing data platform via your corresponding Ibis backend and have access to a number of tables:\n\n1import ibis\n\n2ibis.options.interactive = True\n\n3con = ibis.connect(\"duckdb://penguins.ddb\")\nt = con.table(\"penguins\")\n\n\n1\n\nImport Ibis.\n\n2\n\nConfigure Ibis (interactive).\n\n3\n\nConnect to the data and load a table into a variable.\n\n\n\n\n\nBackend\nA backend provides the connection and basic management of the data platform. Above, we created the con variable that is an instance of a DuckDB backend:\n\ncon\n\n&lt;ibis.backends.duckdb.Backend at 0x1554b8090&gt;\n\n\nIt usually contains some tables:\n\ncon.list_tables()\n\n['penguins']\n\n\nWe can access some internals of Ibis to see what backends are available:\n\n\n\n\n\n\nTip\n\n\n\nDon’t rely on accessing internals of Ibis in production.\n\n\n\nbackends = [entrypoint.name for entrypoint in ibis.util.backend_entry_points()]\nbackends\n\n['bigquery',\n 'clickhouse',\n 'dask',\n 'datafusion',\n 'druid',\n 'duckdb',\n 'flink',\n 'impala',\n 'mssql',\n 'mysql',\n 'oracle',\n 'pandas',\n 'polars',\n 'postgres',\n 'pyspark',\n 'snowflake',\n 'sqlite',\n 'trino']\n\n\n\n\nTable\nYou typically work with a table, conventionally named t for demo or exploratory purposes:\n\nt\n\n┏━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n┃ species ┃ island    ┃ bill_length_mm ┃ bill_depth_mm ┃ flipper_length_mm ┃ body_mass_g ┃ sex    ┃ year  ┃\n┡━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n│ string  │ string    │ float64        │ float64       │ int64             │ int64       │ string │ int64 │\n├─────────┼───────────┼────────────────┼───────────────┼───────────────────┼─────────────┼────────┼───────┤\n│ Adelie  │ Torgersen │           39.1 │          18.7 │               181 │        3750 │ male   │  2007 │\n│ Adelie  │ Torgersen │           39.5 │          17.4 │               186 │        3800 │ female │  2007 │\n│ Adelie  │ Torgersen │           40.3 │          18.0 │               195 │        3250 │ female │  2007 │\n│ Adelie  │ Torgersen │            nan │           nan │              NULL │        NULL │ NULL   │  2007 │\n│ Adelie  │ Torgersen │           36.7 │          19.3 │               193 │        3450 │ female │  2007 │\n│ Adelie  │ Torgersen │           39.3 │          20.6 │               190 │        3650 │ male   │  2007 │\n│ Adelie  │ Torgersen │           38.9 │          17.8 │               181 │        3625 │ female │  2007 │\n│ Adelie  │ Torgersen │           39.2 │          19.6 │               195 │        4675 │ male   │  2007 │\n│ Adelie  │ Torgersen │           34.1 │          18.1 │               193 │        3475 │ NULL   │  2007 │\n│ Adelie  │ Torgersen │           42.0 │          20.2 │               190 │        4250 │ NULL   │  2007 │\n│ …       │ …         │              … │             … │                 … │           … │ …      │     … │\n└─────────┴───────────┴────────────────┴───────────────┴───────────────────┴─────────────┴────────┴───────┘\n\n\n\nWhen working with many tables, you should name them descriptively.\n\n\nSchema\nA table has a schema that Ibis maps to the data platform’s data types:\n\nt.schema()\n\nibis.Schema {\n  species            string\n  island             string\n  bill_length_mm     float64\n  bill_depth_mm      float64\n  flipper_length_mm  int64\n  body_mass_g        int64\n  sex                string\n  year               int64\n}"
  },
  {
    "objectID": "posts/llms-and-data-pt0/index.html#llms-and-data-marvin-and-ibis",
    "href": "posts/llms-and-data-pt0/index.html#llms-and-data-marvin-and-ibis",
    "title": "An introduction to Marvin and Ibis",
    "section": "LLMs and data: Marvin and Ibis",
    "text": "LLMs and data: Marvin and Ibis\nYou can use Marvin and Ibis together to easily apply LLMs to data.\n\nfrom ibis.expr.schema import Schema\nfrom ibis.expr.types.relations import Table\n\n@marvin.ai_fn\ndef sql_select(\n    text: str, table_name: str = t.get_name(), schema: Schema = t.schema()\n) -&gt; str:\n    \"\"\"writes the SQL SELECT statement to query the table according to the text\"\"\"\n\n\nquery = \"the unique combination of species and islands\"\nsql = sql_select(query).strip(\";\")\nsql\n\n'SELECT DISTINCT species, island FROM penguins'\n\n\n\nt.sql(sql)\n\n┏━━━━━━━━━━━┳━━━━━━━━━━━┓\n┃ species   ┃ island    ┃\n┡━━━━━━━━━━━╇━━━━━━━━━━━┩\n│ string    │ string    │\n├───────────┼───────────┤\n│ Adelie    │ Torgersen │\n│ Adelie    │ Biscoe    │\n│ Adelie    │ Dream     │\n│ Gentoo    │ Biscoe    │\n│ Chinstrap │ Dream     │\n└───────────┴───────────┘\n\n\n\n\n\nCode\n1sleep(3)\n\n\n\n1\n\nAvoid rate-limiting by waiting.\n\n\n\n\n\nt.sql(sql_select(query + \" and include their counts in from highest to lowest\").strip(\";\"))\n\n┏━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━┓\n┃ species   ┃ island    ┃ count ┃\n┡━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━┩\n│ string    │ string    │ int64 │\n├───────────┼───────────┼───────┤\n│ Gentoo    │ Biscoe    │   124 │\n│ Chinstrap │ Dream     │    68 │\n│ Adelie    │ Dream     │    56 │\n│ Adelie    │ Torgersen │    52 │\n│ Adelie    │ Biscoe    │    44 │\n└───────────┴───────────┴───────┘"
  },
  {
    "objectID": "posts/llms-and-data-pt0/index.html#next-steps",
    "href": "posts/llms-and-data-pt0/index.html#next-steps",
    "title": "An introduction to Marvin and Ibis",
    "section": "Next steps",
    "text": "Next steps\nYou can get involved with Ibis Birdbrain, our open-source data & AI project for building next-generation natural language interfaces to data.\nRead the next post in this series."
  },
  {
    "objectID": "posts/llms-and-data-pt2/index.html",
    "href": "posts/llms-and-data-pt2/index.html",
    "title": "Calls and computations",
    "section": "",
    "text": "# | code-fold: true\n1import ibis\nimport marvin\n\nfrom dotenv import load_dotenv\n\n2load_dotenv()\n\n3con = ibis.connect(\"duckdb://penguins.ddb\")\nt = ibis.examples.penguins.fetch()\nt = con.create_table(\"penguins\", t.to_pyarrow(), overwrite=True)\n\n1\n\nImport the libraries we need.\n\n2\n\nLoad the environment variable to setup Marvin to call our OpenAI account.\n\n3\n\nSetup the demo datain an Ibis backend.\n\n\n1import ibis\nimport marvin\n\nfrom ibis.expr.schema import Schema\nfrom ibis.expr.types.relations import Table\n\n2ibis.options.interactive = True\nmarvin.settings.llm_model = \"openai/gpt-4\"\n\n3con = ibis.connect(\"duckdb://penguins.ddb\")\nt = con.table(\"penguins\")\n\n1\n\nImport Ibis and Marvin.\n\n2\n\nConfigure Ibis (interactive) and Marvin (GPT-4).\n\n3\n\nConnect to the data and load a table into a variable.\n\n\n1@marvin.ai_fn\ndef _generate_sql_select(\n    text: str, table_name: str, table_schema: Schema\n) -&gt; str:\n    \"\"\"Generate SQL SELECT from text.\"\"\"\n\n\n2def sql_from_text(text: str, t: Table) -&gt; Table:\n    \"\"\"Run SQL from text.\"\"\"\n    return t.sql(_generate_sql_select(text, t.get_name(), t.schema()).strip(\";\"))\n\n1\n\nA non-deterministic, LLM-powered AI function.\n\n2\n\nA deterministic, human-authored function that calls the AI function.\n\n\nt2 = sql_from_text(\"the unique combination of species and islands\", t)\nt2\nt3 = sql_from_text(\n    \"the unique combination of species and islands, with their counts, ordered from highest to lowest, and name that column just 'count'\",\n    t,\n)\nt3"
  },
  {
    "objectID": "posts/llms-and-data-pt2/index.html#introduction",
    "href": "posts/llms-and-data-pt2/index.html#introduction",
    "title": "Calls and computations",
    "section": "",
    "text": "# | code-fold: true\n1import ibis\nimport marvin\n\nfrom dotenv import load_dotenv\n\n2load_dotenv()\n\n3con = ibis.connect(\"duckdb://penguins.ddb\")\nt = ibis.examples.penguins.fetch()\nt = con.create_table(\"penguins\", t.to_pyarrow(), overwrite=True)\n\n1\n\nImport the libraries we need.\n\n2\n\nLoad the environment variable to setup Marvin to call our OpenAI account.\n\n3\n\nSetup the demo datain an Ibis backend.\n\n\n1import ibis\nimport marvin\n\nfrom ibis.expr.schema import Schema\nfrom ibis.expr.types.relations import Table\n\n2ibis.options.interactive = True\nmarvin.settings.llm_model = \"openai/gpt-4\"\n\n3con = ibis.connect(\"duckdb://penguins.ddb\")\nt = con.table(\"penguins\")\n\n1\n\nImport Ibis and Marvin.\n\n2\n\nConfigure Ibis (interactive) and Marvin (GPT-4).\n\n3\n\nConnect to the data and load a table into a variable.\n\n\n1@marvin.ai_fn\ndef _generate_sql_select(\n    text: str, table_name: str, table_schema: Schema\n) -&gt; str:\n    \"\"\"Generate SQL SELECT from text.\"\"\"\n\n\n2def sql_from_text(text: str, t: Table) -&gt; Table:\n    \"\"\"Run SQL from text.\"\"\"\n    return t.sql(_generate_sql_select(text, t.get_name(), t.schema()).strip(\";\"))\n\n1\n\nA non-deterministic, LLM-powered AI function.\n\n2\n\nA deterministic, human-authored function that calls the AI function.\n\n\nt2 = sql_from_text(\"the unique combination of species and islands\", t)\nt2\nt3 = sql_from_text(\n    \"the unique combination of species and islands, with their counts, ordered from highest to lowest, and name that column just 'count'\",\n    t,\n)\nt3"
  },
  {
    "objectID": "posts/llms-and-data-pt2/index.html#summary",
    "href": "posts/llms-and-data-pt2/index.html#summary",
    "title": "Calls and computations",
    "section": "Summary",
    "text": "Summary\nTo summarize this post:\nfrom rich import print\nfrom pydantic import BaseModel, Field\n\nwith open(\"index.qmd\", \"r\") as f:\n    self_text = f.read()\n\n# save some money and avoid rate limiting\nmarvin.settings.llm_model = \"openai/gpt-3.5-turbo-16k\"\n\n@marvin.ai_model\nclass Summary(BaseModel):\n    \"\"\"Summary of text.\"\"\"\n\n    summary_line: str = Field(..., description=\"The one-line summary of the text.\")\n    summary_paragraph: str = Field(\n        ..., description=\"The one-paragraph summary of the text.\"\n    )\n    conclusion: str = Field(\n        ..., description=\"The conclusion the reader should draw from the text.\"\n    )\n    key_points: list[str] = Field(..., description=\"The key points of the text.\")\n    critiques: list[str] = Field(\n        ..., description=\"Professional, fair critiques of the text.\"\n    )\n    suggested_improvements: list[str] = Field(\n        ..., description=\"Suggested improvements for the text.\"\n    )\n    sentiment: float = Field(..., description=\"The sentiment of the text.\")\n    sentiment_label: str = Field(..., description=\"The sentiment label of the text.\")\n    author_bias: str = Field(..., description=\"The author bias of the text.\")\n\n\nprint(Summary(self_text))"
  },
  {
    "objectID": "posts/llms-and-data-pt2/index.html#next-steps",
    "href": "posts/llms-and-data-pt2/index.html#next-steps",
    "title": "Calls and computations",
    "section": "Next steps",
    "text": "Next steps\nYou can get involved with Ibis Birdbrain, our open-source data & AI project for building next-generation natural language interfaces to data.\nRead the next post in this series."
  }
]